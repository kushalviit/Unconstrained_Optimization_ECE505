{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ECE-505 Computer Project 1\n",
    "### Due Date Nov-6 2018\n",
    "\n",
    "Step 1: Importing necessary libraries for all the necessary modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PART1-Algorithmic Implementation\n",
    "#### 1.All the Optimization Algorithm\n",
    "Details of problem statement for implementing Steepest Gradient Descent Method is available in the file \"Computer Project I description.pdf\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class unconstrained_optimizer:\n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    \n",
    "    #function is the mathematical function that needs to be optimized\n",
    "    #gradient is the gadient of the mathematical function.\n",
    "    #line_search is method of finding alpha\n",
    "    def Steepest_Gradient_Descent_Method(self,function,gradient,line_search,\n",
    "                                         linear_first_derivative,condition_check,\n",
    "                                         epsilon,Iter_max,seed_x,linear_second_derivative=None,condition_param=0.5,seed_alpha=0.5,in_param=None,gamma_param=None):\n",
    "        #List to store values to be printed at each iteration\n",
    "        grad_value=[]\n",
    "        x_value=[]\n",
    "        alpha_value=[]\n",
    "        next_x=np.array(seed_x)\n",
    "        current_alpha_value=seed_alpha\n",
    "        for i in range(Iter_max):\n",
    "            #print(\"Iteration:\")\n",
    "            #print(i)\n",
    "            current_x=next_x\n",
    "            current_grad_value=gradient(current_x,in_param,gamma_param)\n",
    "            x_value.append(current_x)\n",
    "            grad_value.append(current_grad_value)\n",
    "            f_of_x=function(current_x,in_param,gamma_param)\n",
    "            criteria=np.linalg.norm(current_grad_value,2)/(1+np.absolute(f_of_x))\n",
    "            \n",
    "            if criteria <= epsilon:\n",
    "                print(\"Criteria of epsilon met at i:\")\n",
    "                print(i)\n",
    "                return[x_value,grad_value,alpha_value,criteria]\n",
    "            if i==25 and condition_param<1e-3:\n",
    "                condition_param=0.8\n",
    "                alpha=0.9\n",
    "            elif i==50 and condition_param<1e-3:\n",
    "                condition_param=0.8\n",
    "                alpha=0.9\n",
    "            elif i==100 and condition_param<1e-2:\n",
    "                condition_param=0.8\n",
    "                alpha=0.9\n",
    "            elif i==200 and condition_param<1e-1:\n",
    "                condition_param=0.8\n",
    "                alpha=0.9\n",
    "            elif i==300:\n",
    "                alpha=1.5\n",
    "            elif i==500 :\n",
    "                condition_param=0.8\n",
    "                alpha=1.5\n",
    "            elif i==700:\n",
    "                alpha=1.5\n",
    "            \n",
    "            p=-current_grad_value\n",
    "            current_alpha_value=line_search(current_x,p,current_alpha_value,function,current_grad_value, \n",
    "                                            linear_first_derivative,linear_second_derivative,condition_check,\n",
    "                                            (condition_param),in_param,gamma_param)\n",
    "            alpha_value.append(current_alpha_value)\n",
    "            next_x=current_x+(current_alpha_value*p)\n",
    "        \n",
    "        print(\"Maximum iteration reached.Criteria of epsilon not met\")\n",
    "        current_x=next_x\n",
    "        current_grad_value=gradient(current_x,in_param,gamma_param)\n",
    "        x_value.append(current_x)\n",
    "        grad_value.append(current_grad_value)\n",
    "        criteria=np.linalg.norm(current_grad_value,2)/(1+np.linalg.norm(current_grad_value,1))        \n",
    "        return[x_value,grad_value,alpha_value,criteria]\n",
    "    \n",
    "    \n",
    "    def Newtons_Method(self,function,gradient_function,hessian_function,epsilon,Iter_max,seed_x,in_param=None,gamma_param=None):\n",
    "        x_value=[]\n",
    "        grad_value=[]\n",
    "        direction_value=[]\n",
    "        next_x=np.array(seed_x)\n",
    "        for i in range(Iter_max):\n",
    "            #print(\"Iteration :\")\n",
    "            #print(i)\n",
    "            current_x_value=next_x\n",
    "            current_grad_value=gradient_function(current_x_value,in_param,gamma_param)\n",
    "            f_of_x=function(current_x_value,in_param,gamma_param)\n",
    "            criteria=np.linalg.norm(current_grad_value,2)/(1+np.absolute(f_of_x))\n",
    "            x_value.append(current_x_value)\n",
    "            grad_value.append(current_grad_value)\n",
    "            if criteria <= epsilon:\n",
    "                print(\"Criteria of epsilon met at i:\")\n",
    "                print(i)\n",
    "                return[x_value,grad_value,direction_value,criteria]\n",
    "            current_hessian_value=hessian_function(current_x_value,in_param,gamma_param)\n",
    "            if np.linalg.det(current_hessian_value)<1e-5:\n",
    "                print(\"Warning: Hessian Matrix is Singluar for the current estimate of X!!!!!\")\n",
    "            \n",
    "            current_direction_value=np.linalg.lstsq(current_hessian_value,current_grad_value)[0]\n",
    "            direction_value.append(current_direction_value)\n",
    "            current_hessian_inv=np.linalg.pinv(current_hessian_value)\n",
    "            next_x=current_x_value-current_hessian_inv.dot(current_direction_value)\n",
    "            \n",
    "        print(\"Maximum iteration reached.Criteria of epsilon not met\")\n",
    "        current_x_value=next_x\n",
    "        current_grad_value=gradient_function(current_x_value,in_param,gamma_param)\n",
    "        criteria=np.linalg.norm(current_grad_value,2)/(1+np.linalg.norm(current_grad_value,1))\n",
    "        x_value.append(current_x_value)\n",
    "        grad_value.append(current_grad_value)\n",
    "        return[x_value,grad_value,direction_value,criteria]\n",
    "    \n",
    "    def BFGS_Quasi_Newton_Method(self,function,gradient_function,line_search,\n",
    "                                 linear_first_derivative,condition_check,\n",
    "                                 epsilon,Iter_max,seed_Hessian,seed_x,\n",
    "                                 linear_second_derivative=None,condition_param=0.5,seed_alpha=0.5,in_param=None,gamma_param=None):\n",
    "        x_value=[]\n",
    "        grad_value=[]\n",
    "        direction_value=[]\n",
    "        next_x=np.matrix(seed_x).T\n",
    "        next_B=np.matrix(seed_Hessian)\n",
    "        next_gradient=np.matrix(gradient_function(next_x,in_param,gamma_param)).T\n",
    "        alpha=seed_alpha\n",
    "        for i in range(Iter_max):\n",
    "            current_x_value=next_x\n",
    "            current_B=next_B\n",
    "            current_grad_value=next_gradient\n",
    "            x_value.append(current_x_value)\n",
    "            grad_value.append(current_grad_value)\n",
    "            f_of_x=function(current_x_value,in_param,gamma_param)\n",
    "            criteria=np.linalg.norm(current_grad_value,2)/(1+np.absolute(f_of_x))\n",
    "            if criteria <= epsilon:\n",
    "                print(\"Criteria of epsilon met at i:\")\n",
    "                print(i)\n",
    "                return[x_value,grad_value,direction_value,criteria]\n",
    "            if np.linalg.det(current_B)<1e-5:\n",
    "                print(\"Warning:B matrix is Singluar for the current estimate of X!!!!!\")\n",
    "            \n",
    "            current_direction_value=np.linalg.lstsq(np.squeeze(np.asarray(current_B)),-1*np.squeeze(np.asarray(current_grad_value)))[0]\n",
    "            current_direction_value=np.matrix(current_direction_value).T\n",
    "            direction_value.append(current_direction_value)\n",
    "            alpha=line_search(current_x_value,current_direction_value,alpha,function,current_grad_value, \n",
    "                                            linear_first_derivative,linear_second_derivative,condition_check,\n",
    "                                            condition_param,in_param,gamma_param)\n",
    "            next_x=current_x_value+(alpha*current_direction_value)\n",
    "            next_gradient=np.matrix(gradient_function(next_x,in_param,gamma_param)).T\n",
    "            s_k=next_x-current_x_value\n",
    "            y_k=next_gradient-current_grad_value\n",
    "            next_B=current_B-((((current_B*s_k)*(current_B*s_k).T)/(s_k.T*current_B*s_k)))+((y_k*y_k.T)/(y_k.T*s_k))\n",
    "            \n",
    "            \n",
    "        \n",
    "        print(\"Maximum iteration reached.Criteria of epsilon not met\")\n",
    "        current_x_value=next_x\n",
    "        current_grad_value=gradient_function(current_x_value,in_param,gamma_param)\n",
    "        criteria=np.linalg.norm(current_grad_value,2)/(1+np.linalg.norm(current_grad_value,1))\n",
    "        x_value.append(current_x_value)\n",
    "        grad_value.append(current_grad_value)\n",
    "        return[x_value,grad_value,direction_value,criteria]\n",
    "     \n",
    "\n",
    "    def Conjugate_Gradient_Descent_Method(self,function,gradient_function,hessian_function,\n",
    "                                          epsilon,Iter_max,seed_x,in_param=None,gamma_param=None):\n",
    "        x_value=[]\n",
    "        grad_value=[]\n",
    "        direction_value=[]\n",
    "        next_x=np.matrix(seed_x).T\n",
    "        next_gradient=np.matrix(gradient_function(next_x,in_param,gamma_param)).T\n",
    "        next_direction=-1*next_gradient\n",
    "        for i in range(Iter_max):\n",
    "            current_x=next_x\n",
    "            current_gradient=next_gradient\n",
    "            current_direction=next_direction\n",
    "            x_value.append(current_x)\n",
    "            grad_value.append(current_gradient)\n",
    "            direction_value.append(current_direction)\n",
    "            f_of_x=function(current_x,in_param,gamma_param)\n",
    "            criteria=np.linalg.norm(current_gradient,2)/(1+np.absolute(f_of_x))\n",
    "            \n",
    "            if criteria <= epsilon:\n",
    "                print(\"Criteria of epsilon met at i:\")\n",
    "                print(i)\n",
    "                return[x_value,grad_value,direction_value,criteria]\n",
    "           \n",
    "            alpha=-1*np.asscalar((current_direction.T*current_gradient)/(current_direction.T*np.matrix(hessian_function(current_x,in_param,gamma_param))*current_direction))\n",
    "            next_x=current_x+alpha*current_direction\n",
    "            next_gradient=np.matrix(gradient_function(next_x,in_param,gamma_param)).T\n",
    "            beta=np.asscalar((current_direction.T*next_gradient)/(current_direction.T*np.matrix(hessian_function(next_x,in_param,gamma_param))*current_direction))\n",
    "            next_direction=-1*next_gradient+(beta*current_direction)\n",
    "        \n",
    "        print(\"Maximum iteration reached.Criteria of epsilon not met\")\n",
    "        current_x=next_x\n",
    "        current_gradient=next_gradient\n",
    "        current_direction=next_direction\n",
    "        criteria=np.linalg.norm(current_gradient,2)/(1+np.linalg.norm(current_gradient,1))\n",
    "        x_value.append(current_x)\n",
    "        grad_value.append(current_gradient)\n",
    "        direction_value.append(current_direction)\n",
    "        return[x_value,grad_value,direction_value,criteria]\n",
    "    \n",
    "\n",
    "def Newton_line_search(x,p,alpha,function,grad_val,linear_first_derivative,linear_second_derivative,condition_check,condition_param,in_param,gamma_param):\n",
    "    next_alpha=alpha\n",
    "    condition=condition_check(condition_param,function,grad_val,x,p,next_alpha,in_param,gamma_param)\n",
    "    while(condition==False):\n",
    "        current_alpha=next_alpha\n",
    "        first_deri=linear_first_derivative(current_alpha,x,p,in_param,gamma_param)\n",
    "        second_deri=linear_second_derivative(current_alpha,x,p,in_param,gamma_param)\n",
    "        next_alpha=current_alpha-(first_deri/second_deri)\n",
    "        condition=condition_check(condition_param,function,grad_val,x,p,next_alpha,in_param,gamma_param)\n",
    "        \n",
    "    return next_alpha\n",
    "\n",
    "#def secant_line_search(x,p,alpha,function,linear_first_derivative,linear_second_derivative,condition_check,condition_param):\n",
    "#    condition=False\n",
    "#    next_alpha=alpha\n",
    "#    while(condition==False):\n",
    "#        current_alpha=next_alpha\n",
    "#        first_deri=linear_first_derivative(current_alpha,x,p)\n",
    "#        second_deri=linear_second_derivative(current_alpha,x,p)\n",
    "#        next_alpha=current_alpha-(first_deri/second_deri)\n",
    "#        condition=condition_check(condition_param,function,x,p,next_alpha)\n",
    "#        \n",
    "#    return next_alpha   \n",
    "\n",
    "#def Wolfe_Condition(condition_param,function,x,p,next_alpha):\n",
    "#    pass\n",
    "\n",
    "def Armijo_Condition(condition_param,function,grad_val,x,p,alpha,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    grad_val=np.squeeze(np.asarray(grad_val))\n",
    "    LHS=function(x+alpha*p,in_param,gamma_param)\n",
    "    RHS=function(x,in_param,gamma_param)+(condition_param*alpha*np.dot(p,grad_val))\n",
    "    if LHS<=RHS:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Function 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "1\n",
      "[1 1 1]\n",
      "[0. 0. 0.]\n",
      "\n",
      "Newton's Method:\n",
      "Criteria of epsilon met at i:\n",
      "19\n",
      "[1 1 1]\n",
      "[0.5 0.5 0.5]\n",
      "[0.25 0.25 0.25]\n",
      "[0.125 0.125 0.125]\n",
      "[0.0625 0.0625 0.0625]\n",
      "[0.03125 0.03125 0.03125]\n",
      "[0.015625 0.015625 0.015625]\n",
      "[0.0078125 0.0078125 0.0078125]\n",
      "[0.00390625 0.00390625 0.00390625]\n",
      "[0.00195312 0.00195312 0.00195312]\n",
      "[0.00097656 0.00097656 0.00097656]\n",
      "[0.00048828 0.00048828 0.00048828]\n",
      "[0.00024414 0.00024414 0.00024414]\n",
      "[0.00012207 0.00012207 0.00012207]\n",
      "[6.10351562e-05 6.10351562e-05 6.10351562e-05]\n",
      "[3.05175781e-05 3.05175781e-05 3.05175781e-05]\n",
      "[1.52587891e-05 1.52587891e-05 1.52587891e-05]\n",
      "[7.62939453e-06 7.62939453e-06 7.62939453e-06]\n",
      "[3.81469727e-06 3.81469727e-06 3.81469727e-06]\n",
      "[1.90734863e-06 1.90734863e-06 1.90734863e-06]\n",
      "\n",
      "BFGS Method:\n",
      "Criteria of epsilon met at i:\n",
      "1\n",
      "[1 1 1]\n",
      "[0. 0. 0.]\n",
      "\n",
      "CGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "1\n",
      "[1 1 1]\n",
      "[0. 0. 0.]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "def function_1_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=3:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 3\")\n",
    "    else:\n",
    "        return x[0]**2+x[1]**2+x[2]**2\n",
    "\n",
    "def grad_function_1_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=3:\n",
    "        print(len(x))\n",
    "        sys.exit(\"fuction1 can handle only vector of size 3\")\n",
    "    else:\n",
    "        return np.array([2*x[0],2*x[1],2*x[2]])\n",
    "    \n",
    "def hessian_function_1_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=3:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 3\")\n",
    "    else:\n",
    "        return np.array([[2,0,0],[0,2,0],[0,0,2]])\n",
    "\n",
    "def linear_first_derivative_function_1_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    return 2*np.dot(x+alpha*p,p) \n",
    "\n",
    "def linear_second_derivative_function_1_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    return 2*np.dot(p,p)\n",
    "\n",
    "optimize=unconstrained_optimizer()\n",
    "print(\"SGD Method:\")\n",
    "[xval,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(function_1_x,grad_function_1_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_1_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([1,1,1]),linear_second_derivative_function_1_alpha,\n",
    "                                                                          0.5,0.5)\n",
    "print(xval[0])\n",
    "print(xval[1])\n",
    "print()\n",
    "print(\"Newton's Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Newtons_Method(function_1_x,grad_function_1_x,hessian_function_1_x,1e-5,1000,np.array([1,1,1]))\n",
    "\n",
    "\n",
    "for x in x_val:\n",
    "    print(x)\n",
    "print()\n",
    "print(\"BFGS Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.BFGS_Quasi_Newton_Method(function_1_x,grad_function_1_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_1_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([[1,0,0],[0,1,0],[0,0,1]]),np.array([1,1,1]),linear_second_derivative_function_1_alpha,\n",
    "                                                                          0.5,0.5)\n",
    "\n",
    "print(np.squeeze(np.asarray(x_val[0])))\n",
    "print(np.squeeze(np.asarray(x_val[1])))\n",
    "print()\n",
    "print(\"CGD Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Conjugate_Gradient_Descent_Method(function_1_x,grad_function_1_x,hessian_function_1_x,\n",
    "                                                                          1e-5,1000,np.array([1,1,1]))\n",
    "print(np.squeeze(np.asarray(x_val[0])))\n",
    "print(np.squeeze(np.asarray(x_val[1])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Function 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "52\n",
      "First 10 output:\n",
      "[0 0]\n",
      "[0.  0.5]\n",
      "[0.25 0.5 ]\n",
      "[0.375 0.625]\n",
      "[0.5    0.6875]\n",
      "[0.59375 0.75   ]\n",
      "[0.671875 0.796875]\n",
      "[0.734375  0.8359375]\n",
      "[0.78515625 0.8671875 ]\n",
      "[0.82617188 0.89257812]\n",
      "\n",
      "Last 5 output:\n",
      "[0.99995528 0.99997236]\n",
      "[0.99996382 0.99997764]\n",
      "[0.99997073 0.99998191]\n",
      "[0.99997632 0.99998537]\n",
      "[0.99998084 0.99998816]\n",
      "\n",
      "Newton's Method:\n",
      "Criteria of epsilon met at i:\n",
      "54\n",
      "First 10 output:\n",
      "[0 0]\n",
      "[1.5 1. ]\n",
      "[1.   0.75]\n",
      "[1.125 0.875]\n",
      "[1.0625 0.875 ]\n",
      "[1.0625  0.90625]\n",
      "[1.046875 0.921875]\n",
      "[1.0390625 0.9375   ]\n",
      "[1.03125    0.94921875]\n",
      "[1.02539062 0.95898437]\n",
      "\n",
      "Last 5 output:\n",
      "[1.00000652 0.99998944]\n",
      "[1.00000528 0.99999146]\n",
      "[1.00000427 0.99999309]\n",
      "[1.00000345 0.99999441]\n",
      "[1.00000279 0.99999548]\n",
      "\n",
      "BFGS Method:\n",
      "Criteria of epsilon met at i:\n",
      "39\n",
      "First 10 output:\n",
      "[0 0]\n",
      "[0.  0.5]\n",
      "[0.25  0.625]\n",
      "[0.4375  0.71875]\n",
      "[0.578125  0.7890625]\n",
      "[0.68359375 0.84179688]\n",
      "[0.76269531 0.88134766]\n",
      "[0.82202148 0.91101074]\n",
      "[0.86651611 0.93325806]\n",
      "[0.89988708 0.94994354]\n",
      "\n",
      "Last 5 output:\n",
      "[0.9999435  0.99997175]\n",
      "[0.99995762 0.99997881]\n",
      "[0.99996822 0.99998411]\n",
      "[0.99997616 0.99998808]\n",
      "[0.99998212 0.99999106]\n",
      "\n",
      "CGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "33\n",
      "First 10 output:\n",
      "[0 0]\n",
      "[0.  0.5]\n",
      "[0.5 0.5]\n",
      "[0.5  0.75]\n",
      "[0.75 0.75]\n",
      "[0.75  0.875]\n",
      "[0.875 0.875]\n",
      "[0.875  0.9375]\n",
      "[0.9375 0.9375]\n",
      "[0.9375  0.96875]\n",
      "\n",
      "Last 5 output:\n",
      "[0.99993896 0.99996948]\n",
      "[0.99996948 0.99996948]\n",
      "[0.99996948 0.99998474]\n",
      "[0.99998474 0.99998474]\n",
      "[0.99998474 0.99999237]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "def function_2_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return x[0]**2+2*x[1]**2-2*x[0]*x[1]-2*x[1]\n",
    "\n",
    "def grad_function_2_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([2*x[0]-2*x[1],4*x[1]-2*x[0]-2])\n",
    "\n",
    "def hessian_function_2_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    return np.array([[2,-2],[-2,4]])\n",
    "\n",
    "def linear_first_derivative_function_2_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return 2*nx[0]*p[0]+4*nx[1]*p[1]-2*p[0]*nx[1]-2*p[1]*nx[0]-2*p[1]\n",
    "\n",
    "def linear_second_derivative_function_2_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    return 2*p[0]**2+4*p[1]**2-4*p[1]*p[0]\n",
    "\n",
    "optimize=unconstrained_optimizer()\n",
    "print(\"SGD Method:\")\n",
    "[xval,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(function_2_x,grad_function_2_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_2_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([0,0]),linear_second_derivative_function_2_alpha,\n",
    "                                                                          0.01,1)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(48,53):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Newton's Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Newtons_Method(function_2_x,grad_function_2_x,hessian_function_2_x,1e-5,1000,np.array([0,0]))\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(48,53):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"BFGS Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.BFGS_Quasi_Newton_Method(function_2_x,grad_function_2_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_2_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([[1,0],[0,1]]),np.array([0,0]),linear_second_derivative_function_2_alpha,\n",
    "                                                                          0.5,0.5)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(35,40):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"CGD Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Conjugate_Gradient_Descent_Method(function_2_x,grad_function_2_x,hessian_function_2_x,\n",
    "                                                                          1e-5,1000,np.array([0,0]))\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(29,34):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Function 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Method:\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[-1.2  1. ]\n",
      "[-0.9844  1.088 ]\n",
      "[-1.02727157  1.06420867]\n",
      "[-1.02688307  1.06242431]\n",
      "[-1.02608882  1.06083722]\n",
      "[-1.02531149  1.05924143]\n",
      "[-1.02453275  1.05764587]\n",
      "[-1.02375338  1.05605017]\n",
      "[-1.02297336  1.05445433]\n",
      "[-1.02219268  1.05285837]\n",
      "\n",
      "Last 5 output:\n",
      "[0.3225118  0.10092289]\n",
      "[0.32346803 0.10154108]\n",
      "[0.32442122 0.10215918]\n",
      "[0.3253714  0.10277717]\n",
      "[0.32631858 0.10339505]\n",
      "\n",
      "Newtons Method:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[-1.2  1. ]\n",
      "[-1.20499381  1.01388852]\n",
      "[-1.20999516  1.02783251]\n",
      "[-1.2150038   1.04183165]\n",
      "[-1.2200195   1.05588561]\n",
      "[-1.22504202  1.06999405]\n",
      "[-1.23007109  1.08415659]\n",
      "[-1.23510647  1.09837285]\n",
      "[-1.2401479   1.11264241]\n",
      "[-1.24519513  1.12696485]\n",
      "\n",
      "Last 5 output:\n",
      "[-1.75778101  2.86823682]\n",
      "[-1.75740386  2.86694888]\n",
      "[-1.75702663  2.86566094]\n",
      "[-1.75664931  2.86437301]\n",
      "[-1.75627191  2.86308508]\n",
      "\n",
      "BFGS Method\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[-1.2  1. ]\n",
      "[1.25713082 2.00291054]\n",
      "[1.55212035 1.99723008]\n",
      "[1.5520811  1.99721896]\n",
      "[1.55205484 1.99721947]\n",
      "[1.55203072 1.9972279 ]\n",
      "[1.5520086  1.99724359]\n",
      "[1.55198834 1.99726592]\n",
      "[1.5519698 1.9972943]\n",
      "[1.55195285 1.99732815]\n",
      "\n",
      "Last 5 output:\n",
      "[1.55023605 2.07123219]\n",
      "[1.55023428 2.07129879]\n",
      "[1.55023252 2.07136538]\n",
      "[1.55023076 2.07143194]\n",
      "[1.55022899 2.07149849]\n",
      "\n",
      "CGD Method\n",
      "Criteria of epsilon met at i:\n",
      "430\n",
      "First 10 output:\n",
      "[-1.2  1. ]\n",
      "[-1.05669744  1.05849084]\n",
      "[-1.03089399  1.06894906]\n",
      "[-1.02258946  1.06208219]\n",
      "[-1.02571487  1.05823057]\n",
      "[-1.01765258  1.05177035]\n",
      "[-1.02069853  1.04789679]\n",
      "[-1.01284874  1.04179685]\n",
      "[-1.015822    1.03789777]\n",
      "[-1.00816112  1.03212084]\n",
      "\n",
      "Last 5 output:\n",
      "[0.99840926 0.99642664]\n",
      "[0.99825528 0.99650659]\n",
      "[0.99987998 0.9997977 ]\n",
      "[0.99989527 0.99979012]\n",
      "[0.99999004 0.99998294]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def function_3_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return (100*(x[1]-x[0]**2)**2)+((1-x[0])**2)\n",
    "\n",
    "def grad_function_3_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([200*(x[1]-x[0]**2)*(-2*x[0])+(-2*(1-x[0])),200*(x[1]-x[0]**2)])\n",
    "\n",
    "def hessian_function_3_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([[(1200*x[0]**2)-(400*x[1])+2,-400*x[0]],[-400*x[0],200]])\n",
    "\n",
    "def linear_first_derivative_function_3_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return 200*(nx[1]-nx[0]**2)*(p[1]-2*nx[0]*p[0])-2*(1-nx[0])*p[0]\n",
    "\n",
    "def linear_second_derivative_function_3_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return 200*(p[1]-2*nx[0]*p[0])*(-2*p[0]**2)+2*p[0]**2\n",
    "\n",
    "optimize=unconstrained_optimizer()\n",
    "print(\"SGD Method:\")\n",
    "[xval,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(function_3_x,grad_function_3_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_3_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([-1.2,1]),linear_second_derivative_function_3_alpha,\n",
    "                                                                          1e-4,1e-3)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Newtons Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Newtons_Method(function_3_x,grad_function_3_x,hessian_function_3_x,1e-5,1000,np.array([-1.2,1]))\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"BFGS Method\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.BFGS_Quasi_Newton_Method(function_3_x,grad_function_3_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_3_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([[1,0],[0,1]]),np.array([-1.2,1]),linear_second_derivative_function_3_alpha,\n",
    "                                                                          1e-2,1e-2)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i]))) \n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(np.squeeze(np.asarray(x_val[i]))) \n",
    "\n",
    "print()\n",
    "print(\"CGD Method\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Conjugate_Gradient_Descent_Method(function_3_x,grad_function_3_x,hessian_function_3_x,\n",
    "                                                                          1e-5,1000,np.array([-1.2,1]))\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i]))) \n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(425,430):\n",
    "    print(np.squeeze(np.asarray(x_val[i]))) \n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.Function 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Method:\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[ 2 -2]\n",
      "[ 2.         -1.11238142]\n",
      "[ 1.86426414 -1.14016317]\n",
      "[ 1.79057341 -1.10320363]\n",
      "[ 1.72753768 -1.05917593]\n",
      "[ 1.66958811 -1.01433486]\n",
      "[ 1.61498178 -0.97050228]\n",
      "[ 1.56302493 -0.92827407]\n",
      "[ 1.51338567 -0.88782643]\n",
      "[ 1.46587175 -0.84917878]\n",
      "\n",
      "Last 5 output:\n",
      "[ 0.05411242 -0.00031683]\n",
      "[ 0.0540822 -0.0003163]\n",
      "[ 0.05405203 -0.00031577]\n",
      "[ 0.05402192 -0.00031524]\n",
      "[ 0.05399185 -0.00031472]\n",
      "\n",
      "Newtons Method:\n",
      "Warning: Hessian Matrix is Singluar for the current estimate of X!!!!!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[ 2 -2]\n",
      "[ 2. -1.]\n",
      "[0.72222222 0.16666667]\n",
      "[0.72706887 0.14814815]\n",
      "[0.71372632 0.1458695 ]\n",
      "[0.70046602 0.14326597]\n",
      "[0.68695824 0.140622  ]\n",
      "[0.67319521 0.13793004]\n",
      "[0.65916209 0.13518754]\n",
      "[0.64484267 0.1323916 ]\n",
      "\n",
      "Last 5 output:\n",
      "[7.21869364 1.44405927]\n",
      "[7.21735776 1.44379215]\n",
      "[7.21602164 1.44352499]\n",
      "[7.21468527 1.44325777]\n",
      "[7.21334865 1.44299051]\n",
      "\n",
      "BFGS Method:\n",
      "Criteria of epsilon met at i:\n",
      "42\n",
      "First 10 output:\n",
      "[ 2 -2]\n",
      "[ 2.   -0.64]\n",
      "[ 0.92941096 -0.11492916]\n",
      "[ 0.84205814 -0.07869163]\n",
      "[ 0.73979205 -0.05867656]\n",
      "[ 0.65057501 -0.0379798 ]\n",
      "[ 0.57657208 -0.0263396 ]\n",
      "[ 0.51210554 -0.0176988 ]\n",
      "[ 0.456268   -0.01205257]\n",
      "[ 0.40729671 -0.00815999]\n",
      "\n",
      "Last 5 output:\n",
      "[ 1.99657607e-02 -1.53681716e-07]\n",
      "[ 1.79402301e-02 -1.04196351e-07]\n",
      "[ 1.61201974e-02 -7.06452261e-08]\n",
      "[ 1.44848118e-02 -4.78975310e-08]\n",
      "[ 1.30153386e-02 -3.24745718e-08]\n",
      "\n",
      "CGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "379\n",
      "First 10 output:\n",
      "[ 2 -2]\n",
      "[2. 0.]\n",
      "[ 1.66670174 -0.3266323 ]\n",
      "[ 1.44767668 -0.53055574]\n",
      "[ 1.29156975 -0.63114786]\n",
      "[ 0.98957424 -0.58735757]\n",
      "[ 0.99182273 -0.35822011]\n",
      "[ 0.84938158 -0.39407747]\n",
      "[ 0.62360726 -0.08194532]\n",
      "[ 0.53910321 -0.1435904 ]\n",
      "\n",
      "Last 5 output:\n",
      "[1.31079903e-02 4.36314189e-06]\n",
      "[ 1.31023301e-02 -6.77427193e-06]\n",
      "[1.30804691e-02 4.33576008e-06]\n",
      "[ 1.30748444e-02 -6.73175709e-06]\n",
      "[1.30531202e-02 4.30866323e-06]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    }
   ],
   "source": [
    "def function_4_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return (x[0]+x[1])**4 + x[1]**2\n",
    "\n",
    "def grad_function_4_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([4*(x[0]+x[1])**3,4*(x[0]+x[1])**3+ 2*x[1]])\n",
    "    \n",
    "def hessian_function_4_x(x,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([[12*(x[0]+x[1])**2,12*(x[0]+x[1])**2],[12*(x[0]+x[1])**2,12*(x[0]+x[1])**2+2]])\n",
    "\n",
    "def linear_first_derivative_function_4_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return (4*((nx[0]+nx[1])**3)*(p[0]+p[1]))+2*nx[1]*p[1]\n",
    "\n",
    "def linear_second_derivative_function_4_alpha(alpha,x,p,in_param,gamma_param):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return (12*((nx[0]+nx[1])**2)*(p[0]+p[1])**2)+2*p[1]**2\n",
    "\n",
    "optimize=unconstrained_optimizer()\n",
    "print(\"SGD Method:\")\n",
    "[xval,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(function_4_x,grad_function_4_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_4_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([2,-2]),linear_second_derivative_function_4_alpha,\n",
    "                                                                          0.5,10)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Newtons Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Newtons_Method(function_4_x,grad_function_4_x,hessian_function_4_x,1e-5,1000,np.array([2,-2]))\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"BFGS Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.BFGS_Quasi_Newton_Method(function_4_x,grad_function_4_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_4_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([[1,0],[0,1]]),np.array([2,-2]),linear_second_derivative_function_4_alpha,\n",
    "                                                                          1e-5,0.5)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(37,42):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"CGD Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Conjugate_Gradient_Descent_Method(function_4_x,grad_function_4_x,hessian_function_4_x,\n",
    "                                                                          1e-5,1000,np.array([2,-2]))\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(374,379):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.Function 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "863\n",
      "First 10 output:\n",
      "[ 1 -1]\n",
      "[-0.79868803  0.80896625]\n",
      "[ 0.06621275 -0.05672049]\n",
      "[ 0.08750801 -0.06542138]\n",
      "[ 0.11360936 -0.07595373]\n",
      "[ 0.14517635 -0.08848303]\n",
      "[ 0.18256011 -0.1029966 ]\n",
      "[ 0.22542662 -0.11914251]\n",
      "[ 0.27226863 -0.13604422]\n",
      "[ 0.32004521 -0.15220974]\n",
      "\n",
      "Last 5 output:\n",
      "[0.35979201 0.35978705]\n",
      "[0.35979197 0.35978709]\n",
      "[0.35979194 0.35978712]\n",
      "[0.35979191 0.35978716]\n",
      "[0.35979187 0.35978719]\n",
      "\n",
      "Newtons Method:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:90: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[ 1 -1]\n",
      "[ 0.99987159 -0.99986347]\n",
      "[ 0.99974316 -0.99972692]\n",
      "[ 0.99961472 -0.99959035]\n",
      "[ 0.99948626 -0.99945377]\n",
      "[ 0.99935779 -0.99931717]\n",
      "[ 0.99922931 -0.99918055]\n",
      "[ 0.99910081 -0.99904391]\n",
      "[ 0.9989723  -0.99890726]\n",
      "[ 0.99884378 -0.99877059]\n",
      "\n",
      "Last 5 output:\n",
      "[ 0.86485971 -0.85412128]\n",
      "[ 0.86471592 -0.85396292]\n",
      "[ 0.86457211 -0.85380453]\n",
      "[ 0.86442829 -0.85364611]\n",
      "[ 0.86428445 -0.85348767]\n",
      "\n",
      "BFGS Method:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece505p1/lib/python3.7/site-packages/ipykernel_launcher.py:129: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "First 10 output:\n",
      "[ 1 -1]\n",
      "[-0.79868803  0.80896625]\n",
      "[-0.79578635  0.8088569 ]\n",
      "[-0.90324348  0.62290556]\n",
      "[-0.90242128  0.62261102]\n",
      "[-0.90174242  0.62218398]\n",
      "[-0.90107125  0.62174509]\n",
      "[-0.90040137  0.62130572]\n",
      "[-0.89973219  0.62086674]\n",
      "[-0.89906366  0.62042822]\n",
      "\n",
      "Last 5 output:\n",
      "[-0.47693426  0.38712272]\n",
      "[-0.47666554  0.38707661]\n",
      "[-0.47639695  0.3870309 ]\n",
      "[-0.47612847  0.3869856 ]\n",
      "[-0.47586012  0.3869407 ]\n",
      "\n",
      "CGD Method:\n",
      "Criteria of epsilon met at i:\n",
      "223\n",
      "First 10 output:\n",
      "[ 1 -1]\n",
      "[ 0.69591488 -0.69417725]\n",
      "[ 0.50865067 -0.50361441]\n",
      "[ 0.40716523 -0.39541478]\n",
      "[ 0.36972144 -0.34503546]\n",
      "[ 0.3752828  -0.29890963]\n",
      "[ 0.41855431 -0.2967335 ]\n",
      "[ 0.41042529 -0.26440717]\n",
      "[ 0.46322189 -0.24232753]\n",
      "[ 0.44538977 -0.21613861]\n",
      "\n",
      "Last 5 output:\n",
      "[0.35979179 0.35978741]\n",
      "[0.35979158 0.35978739]\n",
      "[0.35979156 0.35978763]\n",
      "[0.35979137 0.35978761]\n",
      "[0.35979135 0.35978783]\n"
     ]
    }
   ],
   "source": [
    "nc=100\n",
    "def function_5_x(x,in_param,gamma_param,c=nc):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return (x[0]-1)**2+(x[1]-1)**2+c*(x[0]**2+x[1]**2-0.25)**2\n",
    "\n",
    "def grad_function_5_x(x,in_param,gamma_param,c=nc):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([(2*(x[0]-1))+(2*c*(x[0]**2+x[1]**2-0.25)*2*x[0]),(2*(x[1]-1))+(2*c*(x[0]**2+x[1]**2-0.25)*2*x[1])])\n",
    "\n",
    "def hessian_function_5_x(x,in_param,gamma_param,c=nc):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(x)!=2:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 2\")\n",
    "    else:\n",
    "        return np.array([[2+2*c*(x[0]**2+x[1]**2-0.25)*2+8*c*x[0]**2,8*c*x[0]*x[1]],[8*c*x[0]*x[1],2+2*c*(x[0]**2+x[1]**2-0.25)*2+8*c*x[1]**2]])\n",
    "\n",
    "\n",
    "def linear_first_derivative_function_5_alpha(alpha,x,p,in_param,gamma_param,c=nc):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return 2*nx[0]*p[0]+2*nx[1]*p[1]+(2*c*(nx[0]**2+nx[1]**2-0.25)*(2*nx[0]*p[0]+2*nx[1]*p[1]))\n",
    "\n",
    "def linear_second_derivative_function_5_alpha(alpha,x,p,in_param,gamma_param,c=nc):\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    p=np.squeeze(np.asarray(p))\n",
    "    nx=x+alpha*p\n",
    "    return 2*p[0]**2+2*p[1]**2+(2*c*(2*nx[0]*p[0]+2*nx[1]*p[1])**2)+(2*c*(nx[0]**2+nx[1]**2-0.25)*2*p[0]**2+2*p[1]**2)\n",
    "\n",
    "optimize=unconstrained_optimizer()\n",
    "print(\"SGD Method:\")\n",
    "[xval,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(function_5_x,grad_function_5_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_5_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([1,-1]),linear_second_derivative_function_5_alpha,\n",
    "                                                                          1e-4,0.5)\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(xval[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(858,863):\n",
    "    print(xval[i])\n",
    "\n",
    "print()\n",
    "print(\"Newtons Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Newtons_Method(function_5_x,grad_function_5_x,hessian_function_5_x,1e-5,1000,np.array([1,-1]))\n",
    "\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(x_val[i])\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(x_val[i])\n",
    "\n",
    "print()\n",
    "print(\"BFGS Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.BFGS_Quasi_Newton_Method(function_5_x,grad_function_5_x,\n",
    "                                                                          Newton_line_search,linear_first_derivative_function_5_alpha,\n",
    "                                                                          Armijo_Condition,\n",
    "                                                                          1e-5,1000,np.array([[1,0],[0,1]]),np.array([1,-1]),linear_second_derivative_function_5_alpha,\n",
    "                                                                          1e-4,0.5)\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(995,1000):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"CGD Method:\")\n",
    "[x_val,grad_val,dir_val,crite]=optimize.Conjugate_Gradient_Descent_Method(function_5_x,grad_function_5_x,hessian_function_5_x,\n",
    "                                                                          1e-5,1000,np.array([1,-1]))\n",
    "print(\"First 10 output:\")\n",
    "for i in range(10):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))\n",
    "print()\n",
    "print(\"Last 5 output:\")\n",
    "for i in range(218,223):\n",
    "    print(np.squeeze(np.asarray(x_val[i])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Application (Optional)\n",
    "Refer to the Report PDF for more details.\n",
    "### Expectation-Maximization Algorithm \n",
    "[EM Algorithm](http://www.rmki.kfki.hu/~banmi/elte/bishop_em.pdf)  (Pages 438 and 439 has been used for reference) is part of MLE used when the marginal probabilietes of data are hard to be optimized\n",
    "\n",
    "##### Assumption Cancerous and Non Cancerous pixels are independent i.e $\\rho$ is zero.\n",
    "\n",
    "\n",
    "step1:  Initialize parameters with seed value.\n",
    "\n",
    "step2:  Find Expection $P(Z=z/x;\\theta)$.\n",
    "\n",
    "step3: Maximize Q with respect to parameters or Minimize Q w.r.t parameters\n",
    "\n",
    "step4: check for convergence of parameters of log likelihood function if yes exit else continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_pdf(inp,mean,variance):\n",
    "    return (1/(2*np.pi*np.sqrt(variance)))*np.exp(-1*((inp-mean)**2/(2*variance)))\n",
    "\n",
    "def marginal_log_likelihood_funtion_x(x,theta):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=theta[0]\n",
    "        mu2=theta[2]\n",
    "        v1=theta[1]\n",
    "        v2=theta[3]\n",
    "        P1=theta[4]\n",
    "        P2=1-theta[4]\n",
    "        gauss1=gaussian_pdf(x,mu1,v1)\n",
    "        gauss2=gaussian_pdf(x,mu2,v2)\n",
    "        return np.sum(np.log(P1*gauss1+P2*gauss2))\n",
    "\n",
    "def Expection_function(x,theta):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=theta[0]\n",
    "        mu2=theta[2]\n",
    "        v1=theta[1]\n",
    "        v2=theta[3]\n",
    "        P=[theta[4],1-theta[4]]\n",
    "        gauss=[gaussian_pdf(x,mu1,v1),gaussian_pdf(x,mu2,v2)]\n",
    "        denominator=P[0]*gauss[0]+P[1]*gauss[1]\n",
    "        return [P[0]*gauss[0]/denominator,P[1]*gauss[1]/denominator]\n",
    "\n",
    "def Q_function(theta,x,gamma):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=theta[0]\n",
    "        mu2=theta[2]\n",
    "        v1=theta[1]\n",
    "        v2=theta[3]\n",
    "        P1=theta[4]\n",
    "        P2=1-theta[4]\n",
    "        gauss1=gaussian_pdf(x,mu1,v1)\n",
    "        gauss2=gaussian_pdf(x,mu2,v2)\n",
    "        Q=np.log(P1*gauss1)*gamma[0]+np.log(P2*gauss2)*gamma[1]\n",
    "        Q=-1*np.sum(Q)\n",
    "        return Q\n",
    "        \n",
    "def grad_Q_function(theta,x,gamma):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=theta[0]\n",
    "        mu2=theta[2]\n",
    "        v1=theta[1]\n",
    "        v2=theta[3]\n",
    "        P1=theta[4]\n",
    "        P2=1-theta[4]\n",
    "        dq_dmu1=-1*np.sum(((x-mu1)/v1)*gamma[0])\n",
    "        dq_dv1=-1*np.sum(((-0.5/v1)+(0.5*(x-mu1)**2/v1**2))*gamma[0])\n",
    "        dq_dmu2=-1*np.sum(((x-mu2)/v2)*gamma[1])\n",
    "        dq_dv2=-1*np.sum(((-0.5/v2)+(0.5*(x-mu2)**2/v2**2))*gamma[1])\n",
    "        dq_dp=-1*np.sum((1/P1)*gamma[0]-(1/P2)*gamma[1])\n",
    "        return np.array([dq_dmu1,dq_dv1,dq_dmu2,dq_dv2,dq_dp])\n",
    "\n",
    "def hessian_Q_function(theta,x,gamma):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    x=np.squeeze(np.asarray(x))\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=theta[0]\n",
    "        mu2=theta[2]\n",
    "        v1=theta[1]\n",
    "        v2=theta[3]\n",
    "        P1=theta[4]\n",
    "        P2=1-theta[4]\n",
    "        d2q_dmu1=-1*np.sum(((-1/v1)*gamma[0]))\n",
    "        d2q_dmu1v1=-1*np.sum((-1*(x-mu1)/v1**2)*gamma[0])\n",
    "        d2q_dv1=-1*np.sum(((0.5/v1**2)+(-1*(x-mu1)**2/v1**3))*gamma[0])\n",
    "        d2q_dmu2=-1*np.sum((-1/v2)*gamma[1])\n",
    "        d2q_dmu2v2=-1*np.sum((-1*(x-mu2)/v2**2)*gamma[1])\n",
    "        d2q_dv2=-1*np.sum(((0.5/v2**2)+(-1*(x-mu2)**2/v2**3))*gamma[1])\n",
    "        d2q_dp=-1*np.sum((-1/P1**2)*gamma[0]-(-1/P2**2)*gamma[1])\n",
    "        return np.array([[d2q_dmu1,d2q_dmu1v1,0,0,0],[d2q_dmu1v1,d2q_dv1,0,0,0],[0,0,d2q_dmu2,d2q_dmu2v2,0],[0,0,d2q_dmu2v2,d2q_dv2,0],[0,0,0,0,d2q_dp]])\n",
    "\n",
    "def linearfd_Q_func_alpha(alpha,theta,theta_p,x,gamma_param):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    theta_p=np.squeeze(np.asarray(theta_p))\n",
    "    nt=theta+alpha*theta_p\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=nt[0]\n",
    "        mu2=nt[2]\n",
    "        v1=nt[1]\n",
    "        v2=nt[3]\n",
    "        P1=nt[4]\n",
    "        P2=1-P1\n",
    "        rval=((theta_p[4]/P1)+(0.5*(theta_p[1]/v1))+(0.5*(v1*2*(x-mu1)*-1*theta_p[0]-(x-mu1)**2*theta_p[1])/v1**2))*gamma_param[0]\n",
    "        rval+=((-1*theta_p[4]/P2)+(0.5*(theta_p[3]/v2))+(0.5*(v2*2*(x-mu2)*-1*theta_p[2]-(x-mu2)**2*theta_p[3])/v2**2))*gamma_param[1]\n",
    "        rval=-1*np.sum(rval)\n",
    "        return rval\n",
    "        \n",
    "def linearsd_Q_func_alpha(alpha,theta,theta_p,x,gamma_param):\n",
    "    theta=np.squeeze(np.asarray(theta))\n",
    "    theta_p=np.squeeze(np.asarray(theta_p))\n",
    "    nt=theta+alpha*theta_p\n",
    "    if len(theta)!=5:\n",
    "        sys.exit(\"fuction1 can handle only vector of size 5\")\n",
    "    else:\n",
    "        mu1=nt[0]\n",
    "        mu2=nt[2]\n",
    "        v1=nt[1]\n",
    "        v2=nt[3]\n",
    "        P1=nt[4]\n",
    "        P2=1-P1\n",
    "        n1=v1*2*(x-mu1)*-1*theta_p[0]-(x-mu1)**2*theta_p[1]\n",
    "        n2=v2*2*(x-mu2)*-1*theta_p[2]-(x-mu2)**2*theta_p[3]\n",
    "        dn1=(v1*2*theta_p[0]**2)\n",
    "        dn2=(v2*2*theta_p[2]**2)\n",
    "        rval=((-1*theta_p[4]**2/P1**2)+(0.5*(-1*theta_p[1]**2/v1**2))+(-1*(v1**2*dn1-n1*2*v1*theta_p[1])/v1**3))*gamma_param[0]\n",
    "        rval+=((theta_p[4]**2/P2**2)+(0.5*(-1*theta_p[3]**2/v2**2))+(-1*(v2**2*dn2-n2*2*v2*theta_p[3])/v2**3))*gamma_param[1]\n",
    "        rval=-1*np.sum(rval)\n",
    "        return rval\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Maximum iteration reached.Criteria of epsilon not met\n",
      "Convergence of Marginal probability has not happened\n",
      "Mean1:\n",
      "120.26131051825456\n",
      "Var1:\n",
      "196.28040276252787\n",
      "Mean2:\n",
      "201.6590417843259\n",
      "Var2:\n",
      "218.19920850398717\n",
      "P:\n",
      "0.6165765961562276\n"
     ]
    }
   ],
   "source": [
    "def E_M_Algorithm(file_name,seed_theta):\n",
    "    x=np.loadtxt(file_name,dtype=int,delimiter='\\n')\n",
    "    optimize=unconstrained_optimizer()\n",
    "    seed_theta=np.array(seed_theta)\n",
    "    inital_p_x_given_theta=marginal_log_likelihood_funtion_x(x,seed_theta)\n",
    "    \n",
    "    if len(seed_theta)!=5:\n",
    "        sys.exit(\"E_M can handle only vector of size 5\")\n",
    "   \n",
    "    for i in range(100):\n",
    "        # Expectation step\n",
    "        gamma=Expection_function(x,seed_theta)\n",
    "        \n",
    "        # Maximization Step/ minimization step\n",
    "            \n",
    "            \n",
    "        [new_theta,graval,alval,crit]=optimize.Steepest_Gradient_Descent_Method(Q_function,grad_Q_function,\n",
    "                                                                         Newton_line_search,linearfd_Q_func_alpha,\n",
    "                                                                         Armijo_Condition,\n",
    "                                                                          1e-5,1000,seed_theta,linearsd_Q_func_alpha,\n",
    "                                                                          1e-4,1e-3,x,gamma)\n",
    "        \n",
    "        \n",
    "        new_p_x_given_theta=marginal_log_likelihood_funtion_x(x,new_theta[-1])\n",
    "        seed_theta=new_theta[-1]\n",
    "        c=np.sqrt((new_p_x_given_theta-inital_p_x_given_theta)**2)\n",
    "        if(c<=1e-5):\n",
    "            print(\"Convergence of Marginal probability has happened\")\n",
    "            return seed_theta\n",
    "        else:\n",
    "            inital_p_x_given_theta=new_p_x_given_theta\n",
    "    \n",
    "    print(\"Convergence of Marginal probability has not happened\")\n",
    "    return seed_theta\n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "theta=E_M_Algorithm(\"image_samples.txt\",[120.3091,185.1229,201.7558,201.440,0.61739])\n",
    "#theta=E_M_Algorithm(\"image_samples.txt\",[100,50,150,50,0.5])\n",
    "print(\"Mean1:\")\n",
    "print(theta[0])\n",
    "print(\"Var1:\")\n",
    "print(theta[1])\n",
    "print(\"Mean2:\")\n",
    "print(theta[2])\n",
    "print(\"Var2:\")\n",
    "print(theta[3])\n",
    "print(\"P:\")\n",
    "print(theta[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
